{
  "file_creation": [
    {
      "pattern": "Create a file named {filename}",
      "intent_template": {
        "action": "run_code",
        "code": "open('{filename}', 'w').close()"
      },
      "variables": [
        "filename"
      ],
      "example_command": "Create a file named Cory.txt",
      "raw_command": "Create a file named Cory.txt"
    }
  ],
  "file_management": [
    {
      "pattern": "Rename all {file_extension} files in {folder_path} to follow pattern {naming_pattern}",
      "intent_template": {
        "action": "run_code",
        "code": "import os\nimport re\n\nfolder = '{folder_path}'\npattern = '{naming_pattern}'\nfile_ext = '.{file_extension}'\n\nif not os.path.exists(folder):\n    print(f\"Folder {folder} does not exist.\")\n    exit(1)\n\n# Get all files with the specified extension\nfiles = [f for f in os.listdir(folder) if f.endswith(file_ext)]\n\n# Create a regex pattern to extract parts if needed\n# Example: if naming_pattern is 'file_YYYY-MM-DD'\nfor i, filename in enumerate(files):\n    # Simple incrementing renaming as default behavior\n    new_name = pattern.replace('INDEX', str(i+1))\n    new_name = new_name.replace('ORIGINAL', os.path.splitext(filename)[0])\n    \n    # If it doesn't have the extension, add it\n    if not new_name.endswith(file_ext):\n        new_name += file_ext\n    \n    old_path = os.path.join(folder, filename)\n    new_path = os.path.join(folder, new_name)\n    \n    os.rename(old_path, new_path)\n    print(f\"Renamed: {filename} -> {new_name}\")\n\nprint(f\"Renamed {len(files)} {file_ext} files in {folder}.\")"
      },
      "variables": [
        "file_extension",
        "folder_path",
        "naming_pattern"
      ],
      "example_command": "Rename all txt files in C:\\Documents to follow pattern file_INDEX"
    },
    {
      "pattern": "Create a set of folders for {project_name} project",
      "intent_template": {
        "action": "run_code",
        "code": "import os\n\nproject_name = '{project_name}'\nbase_dir = os.getcwd()\nproject_dir = os.path.join(base_dir, project_name)\n\n# Common project structure folders\nfolders = [\n    '',  # Project root\n    'src',\n    'docs',\n    'tests',\n    'resources',\n    'config',\n    'build'\n]\n\nfor folder in folders:\n    folder_path = os.path.join(project_dir, folder)\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n        print(f\"Created folder: {folder_path}\")\n    else:\n        print(f\"Folder already exists: {folder_path}\")\n\n# Create a basic README file\nreadme_path = os.path.join(project_dir, 'README.md')\nwith open(readme_path, 'w') as f:\n    f.write(f\"# {project_name}\\n\\nProject description goes here.\\n\")\n    \nprint(f\"\\nProject structure for '{project_name}' has been created successfully.\")"
      },
      "variables": [
        "project_name"
      ],
      "example_command": "Create a set of folders for MyWebApp project"
    },
    {
      "pattern": "Merge contents of all {file_extension} files in {folder_path} into a single file",
      "intent_template": {
        "action": "run_code",
        "code": "import os\nimport csv\nimport pandas as pd\n\nfolder_path = '{folder_path}'\nfile_extension = '.{file_extension}'\noutput_file = os.path.join(folder_path, f'merged{file_extension}')\n\n# Check if the folder exists\nif not os.path.exists(folder_path):\n    print(f\"Folder {folder_path} does not exist.\")\n    exit(1)\n\n# Get all files with the specified extension\nfiles = [f for f in os.listdir(folder_path) if f.endswith(file_extension)]\n\nif not files:\n    print(f\"No {file_extension} files found in {folder_path}.\")\n    exit(0)\n\nprint(f\"Found {len(files)} {file_extension} files.\")\n\n# Handle CSV files\nif file_extension.lower() == '.csv':\n    # Read all CSV files into pandas DataFrames\n    dataframes = []\n    for file in files:\n        file_path = os.path.join(folder_path, file)\n        print(f\"Reading: {file}\")\n        try:\n            df = pd.read_csv(file_path)\n            dataframes.append(df)\n        except Exception as e:\n            print(f\"Error reading {file}: {e}\")\n    \n    # Concatenate all dataframes and save to output file\n    if dataframes:\n        merged_df = pd.concat(dataframes, ignore_index=True)\n        merged_df.to_csv(output_file, index=False)\n        print(f\"\\nSuccessfully merged {len(dataframes)} files into {output_file}\")\n    else:\n        print(\"No valid CSV files to merge.\")\n\n# Handle text files\nelif file_extension.lower() in ['.txt', '.log', '.md']:\n    with open(output_file, 'w') as outfile:\n        for file in files:\n            file_path = os.path.join(folder_path, file)\n            print(f\"Appending: {file}\")\n            try:\n                with open(file_path, 'r') as infile:\n                    outfile.write(f\"\\n--- Content from {file} ---\\n\\n\")\n                    outfile.write(infile.read())\n                    outfile.write(\"\\n\\n\")\n            except Exception as e:\n                print(f\"Error reading {file}: {e}\")\n    \n    print(f\"\\nSuccessfully merged {len(files)} files into {output_file}\")\n\nelse:\n    print(f\"Merging {file_extension} files is not supported.\")"
      },
      "variables": [
        "file_extension",
        "folder_path"
      ],
      "example_command": "Merge contents of all csv files in C:\\Data\\Reports into a single file"
    },
    {
      "pattern": "Search for and delete all {file_pattern} files in {folder_path}",
      "intent_template": {
        "action": "run_code",
        "code": "import os\nimport glob\n\nfolder_path = '{folder_path}'\nfile_pattern = '{file_pattern}'\n\n# Check if the folder exists\nif not os.path.exists(folder_path):\n    print(f\"Folder {folder_path} does not exist.\")\n    exit(1)\n\n# Get the search pattern\nsearch_pattern = os.path.join(folder_path, file_pattern)\nprint(f\"Searching for: {search_pattern}\")\n\n# Find all matching files\nmatching_files = glob.glob(search_pattern, recursive=True)\n\nif not matching_files:\n    print(f\"No files matching '{file_pattern}' found in {folder_path}.\")\n    exit(0)\n\nprint(f\"Found {len(matching_files)} matching files:\")\nfor file in matching_files[:5]:  # Show first 5 files\n    print(f\"- {os.path.basename(file)}\")\n\nif len(matching_files) > 5:\n    print(f\"... and {len(matching_files) - 5} more\")\n\n# Confirm deletion\nconfirm = input(f\"\\nDelete {len(matching_files)} files? (yes/no): \")\nif confirm.lower() not in ['yes', 'y']:\n    print(\"Operation cancelled.\")\n    exit(0)\n\n# Delete the files\ndeleted_count = 0\nfor file in matching_files:\n    try:\n        os.remove(file)\n        deleted_count += 1\n    except Exception as e:\n        print(f\"Error deleting {file}: {e}\")\n\nprint(f\"\\nSuccessfully deleted {deleted_count} files.\")"
      },
      "variables": [
        "file_pattern",
        "folder_path"
      ],
      "example_command": "Search for and delete all *.tmp files in C:\\Temp"
    },
    {
      "pattern": "Copy recently edited files from {source_dir} to {backup_dir} modified in the last {days} days",
      "intent_template": {
        "action": "run_code",
        "code": "import os\nimport shutil\nimport time\nfrom datetime import datetime, timedelta\n\nsource_dir = '{source_dir}'\nbackup_dir = '{backup_dir}'\ndays = int('{days}')\n\n# Check if the source directory exists\nif not os.path.exists(source_dir):\n    print(f\"Source directory {source_dir} does not exist.\")\n    exit(1)\n\n# Create backup directory if it doesn't exist\nif not os.path.exists(backup_dir):\n    os.makedirs(backup_dir)\n    print(f\"Created backup directory: {backup_dir}\")\n\n# Calculate the cutoff time (now - days)\ncutoff_time = time.time() - (days * 24 * 60 * 60)\n\n# Find and copy recently modified files\ncopied_count = 0\nprint(f\"Copying files modified in the last {days} days:\")\n\nfor root, _, files in os.walk(source_dir):\n    for file in files:\n        file_path = os.path.join(root, file)\n        \n        # Get file modification time\n        mod_time = os.path.getmtime(file_path)\n        \n        # Check if file was modified after the cutoff time\n        if mod_time > cutoff_time:\n            # Create relative path to maintain directory structure\n            rel_path = os.path.relpath(file_path, source_dir)\n            backup_path = os.path.join(backup_dir, rel_path)\n            \n            # Create directories if they don't exist\n            os.makedirs(os.path.dirname(backup_path), exist_ok=True)\n            \n            # Copy the file\n            try:\n                shutil.copy2(file_path, backup_path)\n                copied_count += 1\n                mod_date = datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M')\n                print(f\"- {rel_path} (Last modified: {mod_date})\")\n            except Exception as e:\n                print(f\"Error copying {file_path}: {e}\")\n\nprint(f\"\\nSuccessfully copied {copied_count} recently modified files to {backup_dir}.\")"
      },
      "variables": [
        "source_dir",
        "backup_dir",
        "days"
      ],
      "example_command": "Copy recently edited files from C:\\Projects to C:\\Backup modified in the last 7 days"
    }
  ],
  "open_webpage": [
    {
      "pattern": "Generate Python code using Selenium that:- Opens Chrome- Goes to {url}- Waits for page load- Types \"Hello world from my assistant\" in the post composer- Clicks the Tweet buttonAssume the user is already logged in. No markdown. Output as:{ \"action\": \"run_code\", \"code\": \"<python code>\" }.",
      "intent_template": {
        "action": "run_code",
        "code": "from selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\ndriver = webdriver.Chrome(executable_path='chromedriver.exe')\ntry:\n    driver.get('{url}')\n    wait = WebDriverWait(driver, 10)\n    tweet_button = wait.until(EC.presence_of_element_located((By.ID, 'tweetButtonInline')))\n    post_composer = driver.find_element(By.ID, 'react-root')\n    post_composer.send_keys('Hello world from my assistant')\n    tweet_button.click()\n    sleep(5)\nfinally:\n    driver.close()"
      },
      "variables": [
        "url"
      ],
      "example_command": "Generate Python code using Selenium that:- Opens Chrome- Goes to https://x.com- Waits for page load- Types \"Hello world from my assistant\" in the post composer- Clicks the Tweet buttonAssume the user is already logged in. No markdown. Output as:{ \"action\": \"run_code\", \"code\": \"<python code>\" }.",
      "raw_command": "Generate Python code using Selenium that:- Opens Chrome- Goes to https://x.com- Waits for page load- Types \"Hello world from my assistant\" in the post composer- Clicks the Tweet buttonAssume the user is already logged in. No markdown. Output as:{ \"action\": \"run_code\", \"code\": \"<python code>\" }."
    }
  ],
  "web_interaction": [
    {
      "pattern": "Open browser and post a status update to {platform}",
      "intent_template": {
        "action": "run_code",
        "code": "from selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.common.exceptions import TimeoutException\nimport time\n\nplatform = '{platform}'.lower()\n\ntry:\n    # Create browser instance\n    print(\"Starting Chrome browser...\")\n    driver = webdriver.Chrome()\n    \n    # Handle different platforms\n    if 'twitter' in platform or 'x' in platform:\n        print(\"Navigating to X (Twitter)...\")\n        driver.get('https://twitter.com')\n        \n        # Wait for login page or home page to load\n        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '[data-testid=\"tweetTextarea_0\"]')))\n        \n        # Click on the compose tweet box\n        compose_box = driver.find_element(By.CSS_SELECTOR, '[data-testid=\"tweetTextarea_0\"]')\n        compose_box.click()\n        \n        # Type the status update\n        status_text = \"Hello world from my assistant! #Automation\"\n        compose_box.send_keys(status_text)\n        \n        # Click on the tweet button\n        tweet_button = driver.find_element(By.CSS_SELECTOR, '[data-testid=\"tweetButton\"]')\n        tweet_button.click()\n        \n        print(\"Status posted successfully to X (Twitter)!\")\n    \n    elif 'facebook' in platform:\n        print(\"Navigating to Facebook...\")\n        driver.get('https://facebook.com')\n        \n        # Wait for the page to load and find the post composer\n        try:\n            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '[role=\"button\"][aria-label*=\"post\"]')))\n            \n            # Click on create post button\n            create_post = driver.find_element(By.CSS_SELECTOR, '[role=\"button\"][aria-label*=\"post\"]')\n            create_post.click()\n            \n            # Wait for the post composer to appear\n            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '[role=\"textbox\"]')))\n            \n            # Type the status update\n            post_composer = driver.find_element(By.CSS_SELECTOR, '[role=\"textbox\"]')\n            post_composer.send_keys(\"Hello world from my assistant! #Automation\")\n            \n            # Click the post button\n            post_button = driver.find_element(By.CSS_SELECTOR, '[aria-label=\"Post\"]')\n            post_button.click()\n            \n            print(\"Status posted successfully to Facebook!\")\n        except TimeoutException:\n            print(\"Could not find the post composer. You may need to log in first.\")\n    \n    else:\n        print(f\"Platform '{platform}' is not supported. Try 'twitter', 'x', or 'facebook'.\")\n    \n    # Keep the browser open for a moment to see the result\n    time.sleep(5)\n\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\nfinally:\n    # Close the browser\n    print(\"Closing browser...\")\n    driver.quit()"
      },
      "variables": [
        "platform"
      ],
      "example_command": "Open browser and post a status update to Twitter"
    },
    {
      "pattern": "Scrape the top {number} headlines from {website} and save them to a file",
      "intent_template": {
        "action": "run_code",
        "code": "import requests\nfrom bs4 import BeautifulSoup\nimport datetime\nimport os\n\n# Parameters\nwebsite = '{website}'\nnum_headlines = int('{number}')\n\n# Function to clean up URLs\ndef clean_url(url, base_url):\n    if url.startswith('http'):\n        return url\n    elif url.startswith('//'):\n        return 'https:' + url\n    elif url.startswith('/'):\n        return base_url.rstrip('/') + url\n    else:\n        return base_url.rstrip('/') + '/' + url\n\n# Handle different news sites\nif 'cnn.com' in website:\n    url = 'https://www.cnn.com'\n    headline_selector = '.container_lead-plus-headlines__headline'\n    link_selector = 'a'\nelif 'bbc' in website:\n    url = 'https://www.bbc.com/news'\n    headline_selector = '.gs-c-promo-heading'\n    link_selector = 'a'\nelif 'nytimes' in website:\n    url = 'https://www.nytimes.com'\n    headline_selector = 'h3'\n    link_selector = 'a'\nelif 'reuters' in website:\n    url = 'https://www.reuters.com'\n    headline_selector = '.heading__base'\n    link_selector = 'a'\nelse:\n    # Generic selectors as fallback\n    url = website\n    if not url.startswith('http'):\n        url = 'https://' + url\n    headline_selector = 'h1, h2, h3'\n    link_selector = 'a'\n\nprint(f\"Scraping headlines from {url}...\")\n\ntry:\n    # Get the webpage content\n    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n    response = requests.get(url, headers=headers)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    \n    # Find headlines\n    headline_elements = soup.select(headline_selector)\n    \n    headlines = []\n    for element in headline_elements:\n        # Get the headline text\n        headline_text = element.get_text().strip()\n        \n        # Get the link if available\n        link = None\n        link_element = element\n        if link_selector:\n            if element.name != 'a' and element.select_one(link_selector):\n                link_element = element.select_one(link_selector)\n            \n            if link_element.name == 'a' and link_element.has_attr('href'):\n                link = clean_url(link_element['href'], url)\n        \n        if headline_text and len(headline_text) > 10:  # Skip very short texts\n            headlines.append((headline_text, link))\n        \n        if len(headlines) >= num_headlines:\n            break\n    \n    # Create output filename with timestamp\n    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n    domain = url.replace('https://', '').replace('http://', '').split('/')[0]\n    filename = f\"headlines_{domain}_{timestamp}.txt\"\n    \n    # Write headlines to file\n    with open(filename, 'w', encoding='utf-8') as f:\n        f.write(f\"Top {len(headlines)} Headlines from {url}\\n\")\n        f.write(f\"Retrieved on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n        \n        for i, (headline, link) in enumerate(headlines, 1):\n            f.write(f\"{i}. {headline}\\n\")\n            if link:\n                f.write(f\"   Link: {link}\\n\")\n            f.write(\"\\n\")\n    \n    print(f\"Successfully scraped {len(headlines)} headlines from {url}\")\n    print(f\"Headlines saved to {os.path.abspath(filename)}\")\n\nexcept Exception as e:\n    print(f\"Error: {e}\")"
      },
      "variables": [
        "number",
        "website"
      ],
      "example_command": "Scrape the top 5 headlines from BBC and save them to a file"
    },
    {
      "pattern": "Open {website}, log in with my credentials, and download {filename}",
      "intent_template": {
        "action": "run_code",
        "code": "from selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.common.exceptions import TimeoutException\nimport time\nimport os\nimport getpass\n\n# Configuration\nwebsite_url = '{website}'\nif not website_url.startswith('http'):\n    website_url = 'https://' + website_url\n    \nfile_to_download = '{filename}'\n\n# Get credentials securely\nusername = input(\"Enter your username: \")\npassword = getpass.getpass(\"Enter your password: \")\n\n# Set up Chrome download preferences\ndownload_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\nchrome_options = webdriver.ChromeOptions()\nprefs = {\n    \"download.default_directory\": download_dir,\n    \"download.prompt_for_download\": False,\n    \"download.directory_upgrade\": True,\n    \"safebrowsing.enabled\": True\n}\nchrome_options.add_experimental_option(\"prefs\", prefs)\n\ntry:\n    # Start the browser\n    print(f\"Opening {website_url}...\")\n    driver = webdriver.Chrome(options=chrome_options)\n    driver.get(website_url)\n    \n    # Wait for the page to load\n    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n    \n    # Look for common login form elements\n    print(\"Looking for login form...\")\n    \n    # Try to find username/email field\n    username_selectors = [\n        \"input[type='email']\", \n        \"input[type='text'][name*='user']\", \n        \"input[type='text'][name*='email']\",\n        \"input[id*='user']\",\n        \"input[id*='email']\"\n    ]\n    \n    username_field = None\n    for selector in username_selectors:\n        try:\n            username_field = WebDriverWait(driver, 3).until(\n                EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n            )\n            if username_field.is_displayed():\n                break\n        except:\n            continue\n    \n    if not username_field:\n        print(\"Could not find username/email field. Please check the website.\")\n        exit(1)\n    \n    # Enter username\n    username_field.clear()\n    username_field.send_keys(username)\n    print(\"Username entered.\")\n    \n    # Try to find password field\n    password_field = None\n    try:\n        password_field = WebDriverWait(driver, 3).until(\n            EC.presence_of_element_located((By.CSS_SELECTOR, \"input[type='password']\"))\n        )\n    except:\n        print(\"Could not find password field. Please check the website.\")\n        exit(1)\n    \n    # Enter password\n    password_field.clear()\n    password_field.send_keys(password)\n    print(\"Password entered.\")\n    \n    # Try to find login button\n    login_button_selectors = [\n        \"button[type='submit']\",\n        \"input[type='submit']\",\n        \"button[id*='login']\",\n        \"button[id*='sign']\",\n        \"a[id*='login']\",\n        \"a[id*='sign']\"\n    ]\n    \n    login_button = None\n    for selector in login_button_selectors:\n        try:\n            login_button = WebDriverWait(driver, 3).until(\n                EC.element_to_be_clickable((By.CSS_SELECTOR, selector))\n            )\n            if login_button.is_displayed():\n                break\n        except:\n            continue\n    \n    if not login_button:\n        # Try to press Enter on the password field\n        print(\"Could not find login button. Trying to submit the form by pressing Enter.\")\n        password_field.send_keys(\"\\n\")\n    else:\n        # Click the login button\n        login_button.click()\n        print(\"Clicked login button.\")\n    \n    # Wait for login to complete\n    print(\"Waiting for login to complete...\")\n    time.sleep(5)\n    \n    # Check if login was successful by looking for common failure indicators\n    error_indicators = [\n        \"//div[contains(text(), 'incorrect')]\",\n        \"//div[contains(text(), 'failed')]\",\n        \"//span[contains(text(), 'incorrect')]\",\n        \"//span[contains(text(), 'failed')]\",\n        \"//p[contains(text(), 'incorrect')]\",\n        \"//p[contains(text(), 'failed')]\"\n    ]\n    \n    for indicator in error_indicators:\n        try:\n            error_element = driver.find_element(By.XPATH, indicator)\n            if error_element.is_displayed():\n                print(\"Login failed. Please check your credentials.\")\n                exit(1)\n        except:\n            pass\n    \n    print(\"Successfully logged in.\")\n    \n    # Search for and download the file\n    print(f\"Looking for file: {file_to_download}...\")\n    \n    # Try different strategies to find the file\n    # Strategy 1: Look for links with the filename\n    try:\n        file_link = WebDriverWait(driver, 10).until(\n            EC.element_to_be_clickable((By.XPATH, f\"//a[contains(@href, '{file_to_download}')]|//a[contains(text(), '{file_to_download}')]\")),\n        )\n        file_link.click()\n        print(f\"Found and clicked on file link: {file_to_download}\")\n    except TimeoutException:\n        # Strategy 2: Look for a search box\n        try:\n            search_box = WebDriverWait(driver, 5).until(\n                EC.presence_of_element_located((By.CSS_SELECTOR, \"input[type='search'], input[placeholder*='search'], input[aria-label*='search']\"))\n            )\n            search_box.clear()\n            search_box.send_keys(file_to_download)\n            search_box.send_keys(\"\\n\")\n            print(f\"Searched for file: {file_to_download}\")\n            \n            # Wait for search results and try to find the file again\n            time.sleep(3)\n            try:\n                file_link = WebDriverWait(driver, 10).until(\n                    EC.element_to_be_clickable((By.XPATH, f\"//a[contains(@href, '{file_to_download}')]|//a[contains(text(), '{file_to_download}')]\")),\n                )\n                file_link.click()\n                print(f\"Found and clicked on file link after search: {file_to_download}\")\n            except:\n                print(f\"Could not find the file: {file_to_download} after search.\")\n                exit(1)\n        except:\n            print(f\"Could not find the file: {file_to_download} and no search box available.\")\n            exit(1)\n    \n    # Wait for download to complete (simple approach)\n    print(\"Waiting for download to complete...\")\n    time.sleep(10)\n    \n    # Check if file exists in download directory\n    expected_file_path = os.path.join(download_dir, file_to_download)\n    if os.path.exists(expected_file_path):\n        print(f\"File successfully downloaded to: {expected_file_path}\")\n    else:\n        # Try to find files with partial name match\n        all_files = os.listdir(download_dir)\n        matching_files = [f for f in all_files if file_to_download.lower() in f.lower()]\n        \n        if matching_files:\n            for file in matching_files:\n                print(f\"Found downloaded file: {os.path.join(download_dir, file)}\")\n        else:\n            print(f\"Download may not have completed or file has a different name.\")\n            print(f\"Check your downloads folder: {download_dir}\")\n\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\nfinally:\n    # Close the browser\n    print(\"\\nClosing browser...\")\n    driver.quit()"
      },
      "variables": [
        "website",
        "filename"
      ],
      "example_command": "Open dropbox.com, log in with my credentials, and download quarterly_report.pdf"
    },
    {
      "pattern": "Launch Zoom meeting with URL {url} and mute my mic",
      "intent_template": {
        "action": "run_code",
        "code": "import subprocess\nimport time\nimport platform\nimport re\nimport webbrowser\n\n# Process the Zoom URL\nzoom_url = '{url}'\n\n# Ensure URL is properly formatted\nif not zoom_url.startswith(\"http\"):\n    zoom_url = \"https://\" + zoom_url\n\n# Check if it's a zoom URL and extract meeting ID\nzoom_pattern = r'zoom\\.us/j/([0-9]+)'\nmatch = re.search(zoom_pattern, zoom_url)\n\nprint(f\"Launching Zoom meeting: {zoom_url}\")\n\n# Use platform-specific methods to launch Zoom\nsystem = platform.system()\n\nif system == \"Windows\":\n    # For Windows\n    try:\n        # Try to launch directly with the zoom URL protocol\n        if match:\n            meeting_id = match.group(1)\n            subprocess.Popen([\"start\", f\"zoommtg://zoom.us/join?confno={meeting_id}&audio=false\"], shell=True)\n            print(\"Launching Zoom with protocol handler (mic muted)\")\n        else:\n            # Fallback to browser\n            webbrowser.open(zoom_url)\n            print(\"Opened Zoom meeting link in browser\")\n            \n            # Wait for the browser to handle the zoom URL\n            time.sleep(3)\n            \n            # Try to find and press the mute button\n            print(\"Note: You may need to manually mute your microphone\")\n    except Exception as e:\n        print(f\"Error launching Zoom: {e}\")\n        print(\"Falling back to opening in browser\")\n        webbrowser.open(zoom_url)\n\nelif system == \"Darwin\":  # macOS\n    try:\n        # Try to launch directly with the zoom URL protocol\n        if match:\n            meeting_id = match.group(1)\n            subprocess.run([\"open\", f\"zoommtg://zoom.us/join?confno={meeting_id}&audio=false\"])\n            print(\"Launching Zoom with protocol handler (mic muted)\")\n        else:\n            # Fallback to browser\n            webbrowser.open(zoom_url)\n            print(\"Opened Zoom meeting link in browser\")\n            \n            # Wait for the browser to handle the zoom URL\n            time.sleep(3)\n            \n            # Try to find and press the mute button\n            print(\"Note: You may need to manually mute your microphone\")\n    except Exception as e:\n        print(f\"Error launching Zoom: {e}\")\n        print(\"Falling back to opening in browser\")\n        webbrowser.open(zoom_url)\n\nelif system == \"Linux\":\n    try:\n        # For Linux, open in browser\n        webbrowser.open(zoom_url)\n        print(\"Opened Zoom meeting link in browser\")\n        print(\"Note: You may need to manually mute your microphone after joining\")\n    except Exception as e:\n        print(f\"Error opening browser: {e}\")\n\nelse:\n    print(f\"Unsupported operating system: {system}\")\n    print(\"Opening Zoom link in default browser\")\n    webbrowser.open(zoom_url)\n\nprint(\"\\nZoom meeting launched! Remember to check that your mic is muted.\")"
      },
      "variables": [
        "url"
      ],
      "example_command": "Launch Zoom meeting with URL zoom.us/j/123456789 and mute my mic"
    },
    {
      "pattern": "Search Google for {query} and extract the first paragraph of results",
      "intent_template": {
        "action": "run_code",
        "code": "import requests\nfrom bs4 import BeautifulSoup\nimport datetime\nimport re\n\n# Search query\nquery = '{query}'\n\n# Format the search URL\nsearch_url = f\"https://www.google.com/search?q={query.replace(' ', '+')}\"\n\nprint(f\"Searching Google for: {query}\")\nprint(f\"URL: {search_url}\")\n\ntry:\n    # Send request with headers to mimic a browser\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n        'Accept-Language': 'en-US,en;q=0.5',\n        'Referer': 'https://www.google.com/'\n    }\n    \n    response = requests.get(search_url, headers=headers)\n    \n    if response.status_code != 200:\n        print(f\"Error: Status code {response.status_code}\")\n        print(\"Google may be blocking automated requests.\")\n        exit(1)\n    \n    # Parse the HTML\n    soup = BeautifulSoup(response.text, 'html.parser')\n    \n    # Look for search results\n    search_results = soup.select('div.g')\n    if not search_results:\n        # Try alternative selectors for Google's changing layout\n        search_results = soup.select('div[data-hveid]')\n    \n    if not search_results:\n        print(\"Could not find search results. Google may have changed their page structure.\")\n        exit(1)\n    \n    print(f\"Found {len(search_results)} results.\\n\")\n    \n    # Extract first result with its description\n    first_result = None\n    result_url = None\n    result_title = None\n    \n    # Try different selectors for result descriptions\n    for result in search_results:\n        # Look for the title\n        title_elem = result.select_one('h3')\n        \n        # Look for the description\n        desc_elem = result.select_one('div.VwiC3b, span.aCOpRe')\n        \n        if not desc_elem:\n            desc_elem = result.select_one('div[data-content-feature=\"1\"]')\n        \n        # Look for the URL\n        url_elem = result.select_one('a')\n        \n        if title_elem and desc_elem and url_elem and url_elem.has_attr('href'):\n            first_result = desc_elem.get_text().strip()\n            result_title = title_elem.get_text().strip()\n            result_url = url_elem['href']\n            if result_url.startswith('/url?'):\n                url_match = re.search(r'url\\?q=([^&]+)', result_url)\n                if url_match:\n                    result_url = url_match.group(1)\n            break\n    \n    if not first_result:\n        print(\"Could not extract the first paragraph from search results.\")\n        exit(1)\n    \n    # Create output filename with timestamp\n    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n    safe_query = re.sub(r'[^\\w]', '_', query)[:30]\n    filename = f\"search_result_{safe_query}_{timestamp}.txt\"\n    \n    # Write to file\n    with open(filename, 'w', encoding='utf-8') as f:\n        f.write(f\"Google Search: {query}\\n\")\n        f.write(f\"Search Time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n        \n        if result_title:\n            f.write(f\"Title: {result_title}\\n\\n\")\n            \n        if result_url:\n            f.write(f\"Source: {result_url}\\n\\n\")\n            \n        f.write(f\"First Paragraph:\\n{first_result}\\n\")\n    \n    # Also print to console\n    print(f\"Results saved to {filename}\\n\")\n    print(\"First Result:\")\n    if result_title:\n        print(f\"Title: {result_title}\")\n    if result_url:\n        print(f\"URL: {result_url}\")\n    print(\"\\nFirst Paragraph:\")\n    print(first_result)\n    \nexcept Exception as e:\n    print(f\"An error occurred: {e}\")"
      },
      "variables": [
        "query"
      ],
      "example_command": "Search Google for climate change solutions and extract the first paragraph of results"
    }
  ],
  "custom_command": [
    {
      "pattern": "create {number} files named 1 through {number}",
      "intent_template": {
        "action": "run_code",
        "code": "for i in range(1, 11):\n    open(str(i) + '.txt', 'w').close()"
      },
      "variables": [
        "number"
      ],
      "example_command": "create 10 files named 1 through 10",
      "raw_command": "create 10 files named 1 through 10"
    }
  ]
}